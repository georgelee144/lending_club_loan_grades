{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/lending_club_scaled_ml.csv')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop(['grade'],axis= 1)\n",
    "y = df.grade\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "def scoring(x, y, clf):\n",
    "\n",
    "    print(confusion_matrix(y, clf.predict_classes(x)))\n",
    "    print(classification_report(y, clf.predict_classes(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\leero\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x_len = len(X.columns)\n",
    "\n",
    "some_activation = tf.keras.layers.LeakyReLU(alpha=0.3)\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.Dense(x_len, activation=some_activation, input_shape=(x_len,)))\n",
    "model.add(tf.keras.layers.Dense(1000, activation=some_activation))\n",
    "model.add(tf.keras.layers.Dense(2000, activation=some_activation))\n",
    "model.add(tf.keras.layers.Dense(2000, activation=some_activation))\n",
    "model.add(tf.keras.layers.Dense(2500, activation=some_activation))\n",
    "model.add(tf.keras.layers.Dense(7, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='sgd', loss='sparse_categorical_crossentropy',metrics=['accuracy','categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set #0\n",
      "Train on 1259635 samples, validate on 419879 samples\n",
      "Epoch 1/10\n",
      "1259635/1259635 [==============================] - 266s 211us/sample - loss: 0.7953 - acc: 0.6536 - categorical_accuracy: 0.1674 - val_loss: 0.6751 - val_acc: 0.7072 - val_categorical_accuracy: 0.2060\n",
      "Epoch 2/10\n",
      "1259635/1259635 [==============================] - 262s 208us/sample - loss: 0.4966 - acc: 0.7807 - categorical_accuracy: 0.1737 - val_loss: 0.4465 - val_acc: 0.8036 - val_categorical_accuracy: 0.1903\n",
      "Epoch 3/10\n",
      "1259635/1259635 [==============================] - 262s 208us/sample - loss: 0.4354 - acc: 0.8058 - categorical_accuracy: 0.1751 - val_loss: 0.4237 - val_acc: 0.8121 - val_categorical_accuracy: 0.1367\n",
      "Epoch 4/10\n",
      "1259635/1259635 [==============================] - 261s 207us/sample - loss: 0.4041 - acc: 0.8193 - categorical_accuracy: 0.1760 - val_loss: 0.4602 - val_acc: 0.7986 - val_categorical_accuracy: 0.1609\n",
      "Epoch 5/10\n",
      "1259635/1259635 [==============================] - 260s 207us/sample - loss: 0.3839 - acc: 0.8277 - categorical_accuracy: 0.1764 - val_loss: 0.3645 - val_acc: 0.8356 - val_categorical_accuracy: 0.1618\n",
      "Epoch 6/10\n",
      "1259635/1259635 [==============================] - 262s 208us/sample - loss: 0.3702 - acc: 0.8331 - categorical_accuracy: 0.1765 - val_loss: 0.3647 - val_acc: 0.8345 - val_categorical_accuracy: 0.1776\n",
      "Epoch 7/10\n",
      "1259635/1259635 [==============================] - 261s 207us/sample - loss: 0.3590 - acc: 0.8382 - categorical_accuracy: 0.1766 - val_loss: 0.3692 - val_acc: 0.8335 - val_categorical_accuracy: 0.1913\n",
      "Epoch 8/10\n",
      "1259635/1259635 [==============================] - 261s 207us/sample - loss: 0.3498 - acc: 0.8420 - categorical_accuracy: 0.1766 - val_loss: 0.3724 - val_acc: 0.8332 - val_categorical_accuracy: 0.1781\n",
      "Epoch 9/10\n",
      "1259635/1259635 [==============================] - 262s 208us/sample - loss: 0.3426 - acc: 0.8446 - categorical_accuracy: 0.1768 - val_loss: 0.3540 - val_acc: 0.8410 - val_categorical_accuracy: 0.1806\n",
      "Epoch 10/10\n",
      "1259635/1259635 [==============================] - 260s 206us/sample - loss: 0.3360 - acc: 0.8476 - categorical_accuracy: 0.1769 - val_loss: 0.3297 - val_acc: 0.8503 - val_categorical_accuracy: 0.1764\n",
      "[[131584  10845     25      0      0      0      0]\n",
      " [ 12965 205794  22555     50      0      0      1]\n",
      " [   372  17268 203908  13448     12      1      1]\n",
      " [   173    105  12118 106312   4903      4      1]\n",
      " [   152     20    156  17004  39552   1785      8]\n",
      " [    68      9     12    208   4924  13580   1606]\n",
      " [     8      1      0     10     67   3771   1838]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.91    142454\n",
      "           1       0.88      0.85      0.87    241365\n",
      "           2       0.85      0.87      0.86    235010\n",
      "           3       0.78      0.86      0.82    123616\n",
      "           4       0.80      0.67      0.73     58677\n",
      "           5       0.71      0.67      0.69     20407\n",
      "           6       0.53      0.32      0.40      5695\n",
      "\n",
      "    accuracy                           0.85    827224\n",
      "   macro avg       0.78      0.74      0.75    827224\n",
      "weighted avg       0.85      0.85      0.85    827224\n",
      "\n",
      "Set #1\n",
      "Train on 1259635 samples, validate on 419879 samples\n",
      "Epoch 1/10\n",
      "1259635/1259635 [==============================] - 261s 207us/sample - loss: 0.3301 - acc: 0.8500 - categorical_accuracy: 0.1769 - val_loss: 0.3509 - val_acc: 0.8419 - val_categorical_accuracy: 0.1654\n",
      "Epoch 2/10\n",
      "1259635/1259635 [==============================] - 260s 207us/sample - loss: 0.3255 - acc: 0.8520 - categorical_accuracy: 0.1767 - val_loss: 0.3530 - val_acc: 0.8426 - val_categorical_accuracy: 0.1599\n",
      "Epoch 3/10\n",
      "1259635/1259635 [==============================] - 261s 207us/sample - loss: 0.3210 - acc: 0.8542 - categorical_accuracy: 0.1768 - val_loss: 0.3535 - val_acc: 0.8394 - val_categorical_accuracy: 0.1751\n",
      "Epoch 4/10\n",
      "1259635/1259635 [==============================] - 263s 209us/sample - loss: 0.3170 - acc: 0.8558 - categorical_accuracy: 0.1768 - val_loss: 0.3355 - val_acc: 0.8478 - val_categorical_accuracy: 0.1680\n",
      "Epoch 5/10\n",
      "1259635/1259635 [==============================] - 261s 207us/sample - loss: 0.3132 - acc: 0.8576 - categorical_accuracy: 0.1769 - val_loss: 0.3159 - val_acc: 0.8566 - val_categorical_accuracy: 0.1789\n",
      "Epoch 6/10\n",
      "1259635/1259635 [==============================] - 262s 208us/sample - loss: 0.3097 - acc: 0.8589 - categorical_accuracy: 0.1768 - val_loss: 0.3198 - val_acc: 0.8549 - val_categorical_accuracy: 0.1853\n",
      "Epoch 7/10\n",
      "1259635/1259635 [==============================] - 262s 208us/sample - loss: 0.3068 - acc: 0.8605 - categorical_accuracy: 0.1769 - val_loss: 0.3128 - val_acc: 0.8576 - val_categorical_accuracy: 0.1773\n",
      "Epoch 8/10\n",
      "1259635/1259635 [==============================] - 259s 206us/sample - loss: 0.3040 - acc: 0.8618 - categorical_accuracy: 0.1768 - val_loss: 0.3261 - val_acc: 0.8529 - val_categorical_accuracy: 0.1553\n",
      "Epoch 9/10\n",
      "1259635/1259635 [==============================] - 261s 207us/sample - loss: 0.3010 - acc: 0.8632 - categorical_accuracy: 0.1768 - val_loss: 0.3331 - val_acc: 0.8517 - val_categorical_accuracy: 0.1787\n",
      "Epoch 10/10\n",
      "1259635/1259635 [==============================] - 263s 209us/sample - loss: 0.2985 - acc: 0.8643 - categorical_accuracy: 0.1768 - val_loss: 0.3011 - val_acc: 0.8634 - val_categorical_accuracy: 0.1858\n",
      "[[136121   6294     38      1      0      0      0]\n",
      " [ 15742 204004  21580     37      0      1      1]\n",
      " [   383  13394 209529  11688     13      3      0]\n",
      " [   175     84  11563 105379   6410      4      1]\n",
      " [   163      6     75  13744  43901    788      0]\n",
      " [    68      8      4    203   6564  12577    983]\n",
      " [     9      0      0      6    182   4131   1367]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.92    142454\n",
      "           1       0.91      0.85      0.88    241365\n",
      "           2       0.86      0.89      0.88    235010\n",
      "           3       0.80      0.85      0.83    123616\n",
      "           4       0.77      0.75      0.76     58677\n",
      "           5       0.72      0.62      0.66     20407\n",
      "           6       0.58      0.24      0.34      5695\n",
      "\n",
      "    accuracy                           0.86    827224\n",
      "   macro avg       0.79      0.74      0.75    827224\n",
      "weighted avg       0.86      0.86      0.86    827224\n",
      "\n",
      "Set #2\n",
      "Train on 1259635 samples, validate on 419879 samples\n",
      "Epoch 1/10\n",
      "1259635/1259635 [==============================] - 261s 208us/sample - loss: 0.2960 - acc: 0.8651 - categorical_accuracy: 0.1767 - val_loss: 0.2871 - val_acc: 0.8689 - val_categorical_accuracy: 0.1801\n",
      "Epoch 2/10\n",
      "1259635/1259635 [==============================] - 262s 208us/sample - loss: 0.2936 - acc: 0.8663 - categorical_accuracy: 0.1765 - val_loss: 0.2895 - val_acc: 0.8678 - val_categorical_accuracy: 0.1809\n",
      "Epoch 3/10\n",
      "1259635/1259635 [==============================] - 259s 206us/sample - loss: 0.2917 - acc: 0.8672 - categorical_accuracy: 0.1766 - val_loss: 0.3156 - val_acc: 0.8572 - val_categorical_accuracy: 0.1733\n",
      "Epoch 4/10\n",
      "1259635/1259635 [==============================] - 262s 208us/sample - loss: 0.2893 - acc: 0.8682 - categorical_accuracy: 0.1766 - val_loss: 0.3074 - val_acc: 0.8617 - val_categorical_accuracy: 0.1732\n",
      "Epoch 5/10\n",
      "1259635/1259635 [==============================] - 261s 207us/sample - loss: 0.2873 - acc: 0.8693 - categorical_accuracy: 0.1766 - val_loss: 0.3141 - val_acc: 0.8565 - val_categorical_accuracy: 0.1494\n",
      "Epoch 6/10\n",
      "1259635/1259635 [==============================] - 263s 208us/sample - loss: 0.2856 - acc: 0.8699 - categorical_accuracy: 0.1765 - val_loss: 0.3354 - val_acc: 0.8494 - val_categorical_accuracy: 0.1670\n",
      "Epoch 7/10\n",
      "1259635/1259635 [==============================] - 262s 208us/sample - loss: 0.2832 - acc: 0.8708 - categorical_accuracy: 0.1765 - val_loss: 0.3253 - val_acc: 0.8543 - val_categorical_accuracy: 0.1695\n",
      "Epoch 8/10\n",
      "1259635/1259635 [==============================] - 260s 207us/sample - loss: 0.2818 - acc: 0.8714 - categorical_accuracy: 0.1763 - val_loss: 0.3061 - val_acc: 0.8614 - val_categorical_accuracy: 0.1805\n",
      "Epoch 9/10\n",
      "1259635/1259635 [==============================] - 262s 208us/sample - loss: 0.2800 - acc: 0.8722 - categorical_accuracy: 0.1762 - val_loss: 0.3099 - val_acc: 0.8616 - val_categorical_accuracy: 0.1607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10\n",
      "1259635/1259635 [==============================] - 260s 207us/sample - loss: 0.2787 - acc: 0.8730 - categorical_accuracy: 0.1763 - val_loss: 0.2777 - val_acc: 0.8741 - val_categorical_accuracy: 0.1735\n",
      "[[132920   9523     11      0      0      0      0]\n",
      " [  9080 215169  17110      6      0      0      0]\n",
      " [   375  15662 207724  11229     16      4      0]\n",
      " [   184     63   9690 109262   4405     12      0]\n",
      " [   167      8     78  14906  40785   2732      1]\n",
      " [    71      5      5    137   3859  16319     11]\n",
      " [    10      0      0      2     42   5610     31]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93    142454\n",
      "           1       0.89      0.89      0.89    241365\n",
      "           2       0.89      0.88      0.88    235010\n",
      "           3       0.81      0.88      0.84    123616\n",
      "           4       0.83      0.70      0.76     58677\n",
      "           5       0.66      0.80      0.72     20407\n",
      "           6       0.72      0.01      0.01      5695\n",
      "\n",
      "    accuracy                           0.87    827224\n",
      "   macro avg       0.82      0.73      0.72    827224\n",
      "weighted avg       0.87      0.87      0.87    827224\n",
      "\n",
      "Set #3\n",
      "Train on 1259635 samples, validate on 419879 samples\n",
      "Epoch 1/10\n",
      "1259635/1259635 [==============================] - 263s 209us/sample - loss: 0.2780 - acc: 0.8733 - categorical_accuracy: 0.1769 - val_loss: 0.2966 - val_acc: 0.8666 - val_categorical_accuracy: 0.1942\n",
      "Epoch 2/10\n",
      "1259635/1259635 [==============================] - 262s 208us/sample - loss: 0.2766 - acc: 0.8740 - categorical_accuracy: 0.1770 - val_loss: 0.2841 - val_acc: 0.8712 - val_categorical_accuracy: 0.1858\n",
      "Epoch 3/10\n",
      "1259635/1259635 [==============================] - 261s 207us/sample - loss: 0.2747 - acc: 0.8747 - categorical_accuracy: 0.1768 - val_loss: 0.2941 - val_acc: 0.8662 - val_categorical_accuracy: 0.1740\n",
      "Epoch 4/10\n",
      "1259635/1259635 [==============================] - 262s 208us/sample - loss: 0.2728 - acc: 0.8756 - categorical_accuracy: 0.1769 - val_loss: 0.2683 - val_acc: 0.8791 - val_categorical_accuracy: 0.1723\n",
      "Epoch 5/10\n",
      "1259635/1259635 [==============================] - 262s 208us/sample - loss: 0.2711 - acc: 0.8763 - categorical_accuracy: 0.1767 - val_loss: 0.2839 - val_acc: 0.8714 - val_categorical_accuracy: 0.1760\n",
      "Epoch 6/10\n",
      "1259635/1259635 [==============================] - 260s 206us/sample - loss: 0.2701 - acc: 0.8765 - categorical_accuracy: 0.1767 - val_loss: 0.2927 - val_acc: 0.8676 - val_categorical_accuracy: 0.1800\n",
      "Epoch 7/10\n",
      "1259635/1259635 [==============================] - 262s 208us/sample - loss: 0.2685 - acc: 0.8775 - categorical_accuracy: 0.1767 - val_loss: 0.2798 - val_acc: 0.8722 - val_categorical_accuracy: 0.1760\n",
      "Epoch 8/10\n",
      "1259635/1259635 [==============================] - 260s 206us/sample - loss: 0.2671 - acc: 0.8783 - categorical_accuracy: 0.1767 - val_loss: 0.2915 - val_acc: 0.8671 - val_categorical_accuracy: 0.1849\n",
      "Epoch 9/10\n",
      "1259635/1259635 [==============================] - 261s 207us/sample - loss: 0.2655 - acc: 0.8789 - categorical_accuracy: 0.1767 - val_loss: 0.2948 - val_acc: 0.8672 - val_categorical_accuracy: 0.1738\n",
      "Epoch 10/10\n",
      "1259635/1259635 [==============================] - 262s 208us/sample - loss: 0.2641 - acc: 0.8794 - categorical_accuracy: 0.1766 - val_loss: 0.2777 - val_acc: 0.8746 - val_categorical_accuracy: 0.1872\n",
      "[[137712   4738      4      0      0      0      0]\n",
      " [ 15246 206494  19616      9      0      0      0]\n",
      " [   551  14004 211360   9085      9      1      0]\n",
      " [   280    132  11503 104873   6819      9      0]\n",
      " [   217     14     65  10714  46426   1239      2]\n",
      " [    76      8      6     87   5219  14274    737]\n",
      " [    17      0      0      0     47   4557   1074]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.97      0.93    142454\n",
      "           1       0.92      0.86      0.88    241365\n",
      "           2       0.87      0.90      0.89    235010\n",
      "           3       0.84      0.85      0.84    123616\n",
      "           4       0.79      0.79      0.79     58677\n",
      "           5       0.71      0.70      0.71     20407\n",
      "           6       0.59      0.19      0.29      5695\n",
      "\n",
      "    accuracy                           0.87    827224\n",
      "   macro avg       0.80      0.75      0.76    827224\n",
      "weighted avg       0.87      0.87      0.87    827224\n",
      "\n",
      "Set #4\n",
      "Train on 1259635 samples, validate on 419879 samples\n",
      "Epoch 1/10\n",
      "1259635/1259635 [==============================] - 261s 207us/sample - loss: 0.2626 - acc: 0.8802 - categorical_accuracy: 0.1766 - val_loss: 0.3046 - val_acc: 0.8650 - val_categorical_accuracy: 0.1767\n",
      "Epoch 2/10\n",
      "1259635/1259635 [==============================] - 262s 208us/sample - loss: 0.2612 - acc: 0.8805 - categorical_accuracy: 0.1765 - val_loss: 0.2773 - val_acc: 0.8737 - val_categorical_accuracy: 0.1647\n",
      "Epoch 3/10\n",
      "1259635/1259635 [==============================] - 262s 208us/sample - loss: 0.2600 - acc: 0.8813 - categorical_accuracy: 0.1764 - val_loss: 0.2772 - val_acc: 0.8756 - val_categorical_accuracy: 0.1837\n",
      "Epoch 4/10\n",
      "1259635/1259635 [==============================] - 261s 207us/sample - loss: 0.2589 - acc: 0.8819 - categorical_accuracy: 0.1765 - val_loss: 0.3020 - val_acc: 0.8665 - val_categorical_accuracy: 0.1867\n",
      "Epoch 5/10\n",
      "1259635/1259635 [==============================] - 261s 207us/sample - loss: 0.2582 - acc: 0.8820 - categorical_accuracy: 0.1764 - val_loss: 0.2834 - val_acc: 0.8706 - val_categorical_accuracy: 0.1800\n",
      "Epoch 6/10\n",
      "1259635/1259635 [==============================] - 260s 207us/sample - loss: 0.2565 - acc: 0.8827 - categorical_accuracy: 0.1765 - val_loss: 0.2991 - val_acc: 0.8692 - val_categorical_accuracy: 0.1935\n",
      "Epoch 7/10\n",
      "1259635/1259635 [==============================] - 260s 206us/sample - loss: 0.2552 - acc: 0.8835 - categorical_accuracy: 0.1764 - val_loss: 0.2747 - val_acc: 0.8766 - val_categorical_accuracy: 0.1832\n",
      "Epoch 8/10\n",
      "1259635/1259635 [==============================] - 262s 208us/sample - loss: 0.2538 - acc: 0.8841 - categorical_accuracy: 0.1764 - val_loss: 0.2977 - val_acc: 0.8680 - val_categorical_accuracy: 0.1822\n",
      "Epoch 9/10\n",
      "1259635/1259635 [==============================] - 260s 206us/sample - loss: 0.2521 - acc: 0.8849 - categorical_accuracy: 0.1766 - val_loss: 0.2722 - val_acc: 0.8780 - val_categorical_accuracy: 0.1713\n",
      "Epoch 10/10\n",
      "1259635/1259635 [==============================] - 259s 206us/sample - loss: 0.2509 - acc: 0.8854 - categorical_accuracy: 0.1765 - val_loss: 0.2737 - val_acc: 0.8755 - val_categorical_accuracy: 0.1661\n",
      "[[129533  12906     14      1      0      0      0]\n",
      " [  5999 210444  24888     34      0      0      0]\n",
      " [   521   8376 216749   9332     26      3      3]\n",
      " [   261     78  11240 105887   6129     20      1]\n",
      " [   194     13     52  11114  46270   1024     10]\n",
      " [    73      5      5     79   5570  14635     40]\n",
      " [     8      0      0      0     82   5540     65]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.91      0.93    142454\n",
      "           1       0.91      0.87      0.89    241365\n",
      "           2       0.86      0.92      0.89    235010\n",
      "           3       0.84      0.86      0.85    123616\n",
      "           4       0.80      0.79      0.79     58677\n",
      "           5       0.69      0.72      0.70     20407\n",
      "           6       0.55      0.01      0.02      5695\n",
      "\n",
      "    accuracy                           0.87    827224\n",
      "   macro avg       0.80      0.73      0.72    827224\n",
      "weighted avg       0.87      0.87      0.87    827224\n",
      "\n",
      "Set #5\n",
      "Train on 1259635 samples, validate on 419879 samples\n",
      "Epoch 1/10\n",
      "1259635/1259635 [==============================] - 261s 208us/sample - loss: 0.2498 - acc: 0.8862 - categorical_accuracy: 0.1763 - val_loss: 0.2644 - val_acc: 0.8811 - val_categorical_accuracy: 0.1735\n",
      "Epoch 2/10\n",
      "1259635/1259635 [==============================] - 260s 206us/sample - loss: 0.2490 - acc: 0.8861 - categorical_accuracy: 0.1762 - val_loss: 0.2824 - val_acc: 0.8743 - val_categorical_accuracy: 0.1761\n",
      "Epoch 3/10\n",
      "1259635/1259635 [==============================] - 262s 208us/sample - loss: 0.2470 - acc: 0.8872 - categorical_accuracy: 0.1762 - val_loss: 0.2934 - val_acc: 0.8686 - val_categorical_accuracy: 0.1663\n",
      "Epoch 4/10\n",
      "1259635/1259635 [==============================] - 260s 206us/sample - loss: 0.2460 - acc: 0.8880 - categorical_accuracy: 0.1761 - val_loss: 0.2669 - val_acc: 0.8786 - val_categorical_accuracy: 0.1702\n",
      "Epoch 5/10\n",
      "1259635/1259635 [==============================] - 261s 207us/sample - loss: 0.2440 - acc: 0.8886 - categorical_accuracy: 0.1759 - val_loss: 0.2839 - val_acc: 0.8743 - val_categorical_accuracy: 0.1728\n",
      "Epoch 6/10\n",
      "1259635/1259635 [==============================] - 262s 208us/sample - loss: 0.2421 - acc: 0.8893 - categorical_accuracy: 0.1758 - val_loss: 0.2708 - val_acc: 0.8786 - val_categorical_accuracy: 0.1805\n",
      "Epoch 7/10\n",
      "1259635/1259635 [==============================] - 262s 208us/sample - loss: 0.2406 - acc: 0.8900 - categorical_accuracy: 0.1758 - val_loss: 0.2838 - val_acc: 0.8757 - val_categorical_accuracy: 0.1743\n",
      "Epoch 8/10\n",
      "1259635/1259635 [==============================] - 261s 207us/sample - loss: 0.2401 - acc: 0.8903 - categorical_accuracy: 0.1758 - val_loss: 0.2741 - val_acc: 0.8779 - val_categorical_accuracy: 0.1806\n",
      "Epoch 9/10\n",
      "1259635/1259635 [==============================] - 261s 207us/sample - loss: 0.2390 - acc: 0.8910 - categorical_accuracy: 0.1757 - val_loss: 0.2739 - val_acc: 0.8772 - val_categorical_accuracy: 0.1662\n",
      "Epoch 10/10\n",
      "1259635/1259635 [==============================] - 260s 207us/sample - loss: 0.2373 - acc: 0.8916 - categorical_accuracy: 0.1758 - val_loss: 0.2758 - val_acc: 0.8770 - val_categorical_accuracy: 0.1782\n",
      "[[134762   7650     40      0      0      0      2]\n",
      " [ 11043 213264  17048      9      0      1      0]\n",
      " [   375  15122 209781   9708     21      3      0]\n",
      " [   174     61  10730 103106   9503     41      1]\n",
      " [   161      9     92   8225  48803   1384      3]\n",
      " [    69      5      5     30   5751  14424    123]\n",
      " [     6      1      3      1    109   5416    159]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.93    142454\n",
      "           1       0.90      0.88      0.89    241365\n",
      "           2       0.88      0.89      0.89    235010\n",
      "           3       0.85      0.83      0.84    123616\n",
      "           4       0.76      0.83      0.79     58677\n",
      "           5       0.68      0.71      0.69     20407\n",
      "           6       0.55      0.03      0.05      5695\n",
      "\n",
      "    accuracy                           0.88    827224\n",
      "   macro avg       0.79      0.73      0.73    827224\n",
      "weighted avg       0.87      0.88      0.87    827224\n",
      "\n",
      "Set #6\n",
      "Train on 1259635 samples, validate on 419879 samples\n",
      "Epoch 1/10\n",
      "1259635/1259635 [==============================] - 262s 208us/sample - loss: 0.2360 - acc: 0.8924 - categorical_accuracy: 0.1758 - val_loss: 0.3024 - val_acc: 0.8693 - val_categorical_accuracy: 0.1623\n",
      "Epoch 2/10\n",
      "1259635/1259635 [==============================] - 261s 207us/sample - loss: 0.2348 - acc: 0.8927 - categorical_accuracy: 0.1758 - val_loss: 0.2708 - val_acc: 0.8774 - val_categorical_accuracy: 0.1605\n",
      "Epoch 3/10\n",
      "1259635/1259635 [==============================] - 262s 208us/sample - loss: 0.2338 - acc: 0.8930 - categorical_accuracy: 0.1757 - val_loss: 0.2844 - val_acc: 0.8742 - val_categorical_accuracy: 0.1715\n",
      "Epoch 4/10\n",
      "1259635/1259635 [==============================] - 262s 208us/sample - loss: 0.2326 - acc: 0.8937 - categorical_accuracy: 0.1757 - val_loss: 0.2588 - val_acc: 0.8844 - val_categorical_accuracy: 0.1734\n",
      "Epoch 5/10\n",
      "1259635/1259635 [==============================] - 262s 208us/sample - loss: 0.2311 - acc: 0.8944 - categorical_accuracy: 0.1758 - val_loss: 0.2498 - val_acc: 0.8882 - val_categorical_accuracy: 0.1791\n",
      "Epoch 6/10\n",
      "1259635/1259635 [==============================] - 261s 207us/sample - loss: 0.2298 - acc: 0.8950 - categorical_accuracy: 0.1758 - val_loss: 0.2749 - val_acc: 0.8777 - val_categorical_accuracy: 0.1683\n",
      "Epoch 7/10\n",
      "1259635/1259635 [==============================] - 262s 208us/sample - loss: 0.2289 - acc: 0.8953 - categorical_accuracy: 0.1756 - val_loss: 0.2702 - val_acc: 0.8817 - val_categorical_accuracy: 0.1827\n",
      "Epoch 8/10\n",
      "1259635/1259635 [==============================] - 261s 207us/sample - loss: 0.2278 - acc: 0.8962 - categorical_accuracy: 0.1759 - val_loss: 0.3098 - val_acc: 0.8675 - val_categorical_accuracy: 0.1739\n",
      "Epoch 9/10\n",
      "1259635/1259635 [==============================] - 262s 208us/sample - loss: 0.2261 - acc: 0.8967 - categorical_accuracy: 0.1759 - val_loss: 0.3623 - val_acc: 0.8531 - val_categorical_accuracy: 0.1730\n",
      "Epoch 10/10\n",
      "1259635/1259635 [==============================] - 261s 207us/sample - loss: 0.2262 - acc: 0.8969 - categorical_accuracy: 0.1758 - val_loss: 0.3114 - val_acc: 0.8658 - val_categorical_accuracy: 0.1804\n",
      "[[134763   7683      6      0      0      0      2]\n",
      " [ 12914 217601  10845      5      0      0      0]\n",
      " [   371  28289 197558   8785      6      0      1]\n",
      " [   177    243  11992 106893   4295     16      0]\n",
      " [   162     20    102  14180  42674   1531      8]\n",
      " [    70      6      3     92   4765  15426     45]\n",
      " [     6      1      0      3     54   5565     66]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93    142454\n",
      "           1       0.86      0.90      0.88    241365\n",
      "           2       0.90      0.84      0.87    235010\n",
      "           3       0.82      0.86      0.84    123616\n",
      "           4       0.82      0.73      0.77     58677\n",
      "           5       0.68      0.76      0.72     20407\n",
      "           6       0.54      0.01      0.02      5695\n",
      "\n",
      "    accuracy                           0.86    827224\n",
      "   macro avg       0.79      0.72      0.72    827224\n",
      "weighted avg       0.86      0.86      0.86    827224\n",
      "\n",
      "Set #7\n",
      "Train on 1259635 samples, validate on 419879 samples\n",
      "Epoch 1/10\n",
      "1259635/1259635 [==============================] - 261s 207us/sample - loss: 0.2233 - acc: 0.8983 - categorical_accuracy: 0.1757 - val_loss: 0.2721 - val_acc: 0.8797 - val_categorical_accuracy: 0.1865\n",
      "Epoch 2/10\n",
      "1259635/1259635 [==============================] - 260s 206us/sample - loss: 0.2215 - acc: 0.8987 - categorical_accuracy: 0.1758 - val_loss: 0.3148 - val_acc: 0.8647 - val_categorical_accuracy: 0.1513\n",
      "Epoch 3/10\n",
      "1259635/1259635 [==============================] - 260s 207us/sample - loss: 0.2198 - acc: 0.8995 - categorical_accuracy: 0.1759 - val_loss: 0.2748 - val_acc: 0.8808 - val_categorical_accuracy: 0.1766\n",
      "Epoch 4/10\n",
      "1259635/1259635 [==============================] - 263s 208us/sample - loss: 0.2195 - acc: 0.8998 - categorical_accuracy: 0.1757 - val_loss: 0.2682 - val_acc: 0.8817 - val_categorical_accuracy: 0.1775\n",
      "Epoch 5/10\n",
      "1259635/1259635 [==============================] - 260s 207us/sample - loss: 0.2178 - acc: 0.9003 - categorical_accuracy: 0.1758 - val_loss: 0.2753 - val_acc: 0.8801 - val_categorical_accuracy: 0.1695\n",
      "Epoch 6/10\n",
      "1259635/1259635 [==============================] - 260s 207us/sample - loss: 0.2176 - acc: 0.9007 - categorical_accuracy: 0.1759 - val_loss: 0.2819 - val_acc: 0.8782 - val_categorical_accuracy: 0.1820\n",
      "Epoch 7/10\n",
      "1259635/1259635 [==============================] - 259s 206us/sample - loss: 0.2150 - acc: 0.9017 - categorical_accuracy: 0.1757 - val_loss: 0.2633 - val_acc: 0.8856 - val_categorical_accuracy: 0.1792\n",
      "Epoch 8/10\n",
      "1259635/1259635 [==============================] - 260s 206us/sample - loss: 0.2143 - acc: 0.9023 - categorical_accuracy: 0.1758 - val_loss: 0.2883 - val_acc: 0.8798 - val_categorical_accuracy: 0.1761\n",
      "Epoch 9/10\n",
      "1259635/1259635 [==============================] - 257s 204us/sample - loss: 0.2148 - acc: 0.9021 - categorical_accuracy: 0.1757 - val_loss: 0.3083 - val_acc: 0.8693 - val_categorical_accuracy: 0.1800\n",
      "Epoch 10/10\n",
      "1259635/1259635 [==============================] - 256s 203us/sample - loss: 0.2111 - acc: 0.9034 - categorical_accuracy: 0.1757 - val_loss: 0.2735 - val_acc: 0.8825 - val_categorical_accuracy: 0.1822\n",
      "[[137367   5059     28      0      0      0      0]\n",
      " [ 11923 210867  18549     26      0      0      0]\n",
      " [   372  12166 212405  10034     31      2      0]\n",
      " [   178     44  10104 104184   9089     15      2]\n",
      " [   165      4     84   7942  49279   1154     49]\n",
      " [    69      4      3     59   5255  14751    266]\n",
      " [     8      0      0      3     68   5367    249]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94    142454\n",
      "           1       0.92      0.87      0.90    241365\n",
      "           2       0.88      0.90      0.89    235010\n",
      "           3       0.85      0.84      0.85    123616\n",
      "           4       0.77      0.84      0.81     58677\n",
      "           5       0.69      0.72      0.71     20407\n",
      "           6       0.44      0.04      0.08      5695\n",
      "\n",
      "    accuracy                           0.88    827224\n",
      "   macro avg       0.78      0.74      0.74    827224\n",
      "weighted avg       0.88      0.88      0.88    827224\n",
      "\n",
      "Set #8\n",
      "Train on 1259635 samples, validate on 419879 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1259635/1259635 [==============================] - 247s 196us/sample - loss: 0.2101 - acc: 0.9043 - categorical_accuracy: 0.1757 - val_loss: 0.2596 - val_acc: 0.8855 - val_categorical_accuracy: 0.1846\n",
      "Epoch 2/10\n",
      "1259635/1259635 [==============================] - 240s 190us/sample - loss: 0.2090 - acc: 0.9046 - categorical_accuracy: 0.1757 - val_loss: 0.2709 - val_acc: 0.8834 - val_categorical_accuracy: 0.1767\n",
      "Epoch 3/10\n",
      "1259635/1259635 [==============================] - 242s 192us/sample - loss: 0.2070 - acc: 0.9056 - categorical_accuracy: 0.1759 - val_loss: 0.2639 - val_acc: 0.8861 - val_categorical_accuracy: 0.1724\n",
      "Epoch 4/10\n",
      "1259635/1259635 [==============================] - 241s 192us/sample - loss: 0.2056 - acc: 0.9060 - categorical_accuracy: 0.1757 - val_loss: 0.2884 - val_acc: 0.8780 - val_categorical_accuracy: 0.1835\n",
      "Epoch 5/10\n",
      "1259635/1259635 [==============================] - 237s 188us/sample - loss: 0.2051 - acc: 0.9063 - categorical_accuracy: 0.1758 - val_loss: 0.2840 - val_acc: 0.8788 - val_categorical_accuracy: 0.1801\n",
      "Epoch 6/10\n",
      "1259635/1259635 [==============================] - 240s 191us/sample - loss: 0.2037 - acc: 0.9071 - categorical_accuracy: 0.1758 - val_loss: 0.2938 - val_acc: 0.8759 - val_categorical_accuracy: 0.1932\n",
      "Epoch 7/10\n",
      "1259635/1259635 [==============================] - 238s 189us/sample - loss: 0.2023 - acc: 0.9077 - categorical_accuracy: 0.1758 - val_loss: 0.2933 - val_acc: 0.8789 - val_categorical_accuracy: 0.1807\n",
      "Epoch 8/10\n",
      "1259635/1259635 [==============================] - 237s 188us/sample - loss: 0.2009 - acc: 0.9082 - categorical_accuracy: 0.1758 - val_loss: 0.3151 - val_acc: 0.8684 - val_categorical_accuracy: 0.1691\n",
      "Epoch 9/10\n",
      "1259635/1259635 [==============================] - 235s 186us/sample - loss: 0.1998 - acc: 0.9092 - categorical_accuracy: 0.1758 - val_loss: 0.2832 - val_acc: 0.8826 - val_categorical_accuracy: 0.1703\n",
      "Epoch 10/10\n",
      "1259635/1259635 [==============================] - 236s 187us/sample - loss: 0.1981 - acc: 0.9096 - categorical_accuracy: 0.1758 - val_loss: 0.2869 - val_acc: 0.8810 - val_categorical_accuracy: 0.1779\n",
      "[[136024   6398     24      8      0      0      0]\n",
      " [  9771 219003  12543     40      8      0      0]\n",
      " [   347  19557 200320  14661    121      4      0]\n",
      " [   166     89   5634 110766   6947     14      0]\n",
      " [   160      9     46  10243  47325    877     17]\n",
      " [    70      4      3     97   5645  14415    173]\n",
      " [     7      1      1      3     61   5405    217]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94    142454\n",
      "           1       0.89      0.91      0.90    241365\n",
      "           2       0.92      0.85      0.88    235010\n",
      "           3       0.82      0.90      0.85    123616\n",
      "           4       0.79      0.81      0.80     58677\n",
      "           5       0.70      0.71      0.70     20407\n",
      "           6       0.53      0.04      0.07      5695\n",
      "\n",
      "    accuracy                           0.88    827224\n",
      "   macro avg       0.80      0.74      0.74    827224\n",
      "weighted avg       0.88      0.88      0.88    827224\n",
      "\n",
      "Set #9\n",
      "Train on 1259635 samples, validate on 419879 samples\n",
      "Epoch 1/10\n",
      "1259635/1259635 [==============================] - 236s 187us/sample - loss: 0.1970 - acc: 0.9099 - categorical_accuracy: 0.1757 - val_loss: 0.2763 - val_acc: 0.8814 - val_categorical_accuracy: 0.1811\n",
      "Epoch 2/10\n",
      "1259635/1259635 [==============================] - 236s 188us/sample - loss: 0.1965 - acc: 0.9108 - categorical_accuracy: 0.1759 - val_loss: 0.2784 - val_acc: 0.8833 - val_categorical_accuracy: 0.1763\n",
      "Epoch 3/10\n",
      "1259635/1259635 [==============================] - 237s 188us/sample - loss: 0.1960 - acc: 0.9106 - categorical_accuracy: 0.1758 - val_loss: 0.2817 - val_acc: 0.8812 - val_categorical_accuracy: 0.1818\n",
      "Epoch 4/10\n",
      "1259635/1259635 [==============================] - 237s 188us/sample - loss: 0.1941 - acc: 0.9115 - categorical_accuracy: 0.1758 - val_loss: 0.2649 - val_acc: 0.8895 - val_categorical_accuracy: 0.1689\n",
      "Epoch 5/10\n",
      "1259635/1259635 [==============================] - 233s 185us/sample - loss: 0.1916 - acc: 0.9124 - categorical_accuracy: 0.1758 - val_loss: 0.3187 - val_acc: 0.8744 - val_categorical_accuracy: 0.1966\n",
      "Epoch 6/10\n",
      "1259635/1259635 [==============================] - 233s 185us/sample - loss: 0.1941 - acc: 0.9119 - categorical_accuracy: 0.1757 - val_loss: 0.2876 - val_acc: 0.8813 - val_categorical_accuracy: 0.1808\n",
      "Epoch 7/10\n",
      "1259635/1259635 [==============================] - 233s 185us/sample - loss: 0.1897 - acc: 0.9132 - categorical_accuracy: 0.1758 - val_loss: 0.2719 - val_acc: 0.8874 - val_categorical_accuracy: 0.1742\n",
      "Epoch 8/10\n",
      "1259635/1259635 [==============================] - 232s 184us/sample - loss: 0.1882 - acc: 0.9139 - categorical_accuracy: 0.1759 - val_loss: 0.2596 - val_acc: 0.8933 - val_categorical_accuracy: 0.1743\n",
      "Epoch 9/10\n",
      "1259635/1259635 [==============================] - 231s 183us/sample - loss: 0.1864 - acc: 0.9148 - categorical_accuracy: 0.1757 - val_loss: 0.2623 - val_acc: 0.8912 - val_categorical_accuracy: 0.1725\n",
      "Epoch 10/10\n",
      "1259635/1259635 [==============================] - 231s 183us/sample - loss: 0.1852 - acc: 0.9154 - categorical_accuracy: 0.1759 - val_loss: 0.2802 - val_acc: 0.8846 - val_categorical_accuracy: 0.1712\n",
      "[[132402  10034     18      0      0      0      0]\n",
      " [  7647 213670  19995     53      0      0      0]\n",
      " [   385   9926 212939  11737     18      0      5]\n",
      " [   178     92   7151 107678   8488     25      4]\n",
      " [   164     11     55   7910  48068   2426     43]\n",
      " [    70      7      3     49   3815  16318    145]\n",
      " [     6      2      0      4     20   5521    142]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.93    142454\n",
      "           1       0.91      0.89      0.90    241365\n",
      "           2       0.89      0.91      0.90    235010\n",
      "           3       0.84      0.87      0.86    123616\n",
      "           4       0.80      0.82      0.81     58677\n",
      "           5       0.67      0.80      0.73     20407\n",
      "           6       0.42      0.02      0.05      5695\n",
      "\n",
      "    accuracy                           0.88    827224\n",
      "   macro avg       0.78      0.75      0.74    827224\n",
      "weighted avg       0.88      0.88      0.88    827224\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for number in range(10):\n",
    "    print('Set #%s' %number)\n",
    "    model.fit(X_train, y_train, validation_split=0.25, epochs=10)\n",
    "    scoring(X_test,y_test,model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
